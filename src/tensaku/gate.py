# -*- coding: utf-8 -*-
"""
@module     tensaku.gate
@role       HITLã‚²ãƒ¼ãƒˆã®è–„ã„ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ã€‚
@overview   devã§æ¸©åº¦æ ¡æ­£â†’ä¿¡é ¼åº¦â†’Ï„æ¢ç´¢ï¼ˆCSE<=Îµ ã‚’æº€ãŸã— coverage æœ€å¤§ï¼‰â†’pool/testã¸å›ºå®šé©ç”¨ã€‚
@inputs     - YAMLè¨­å®š: data_dir, outputs, gate.{conf_name,cse_abs_err,eps_list,accept_policy,pseudo_label_thresh}, calibration, confidence
            - {outputs}/dev_detail.csv        : y_true, y_pred, conf_* [ä»»æ„: logits_*]
            - {outputs}/preds_detail.csv      : id, y_pred, conf_*     [ä»»æ„: logits_*]
@outputs    - {outputs}/hitl_summary.csv      : eps, tau, coverage, CSE, RMSE, QWK, ...
            - {outputs}/accept.csv, hold.csv  : id, y_pred, conf, ...
            - {outputs}/curve_coverage_rmse.png
            - {outputs}/curve_coverage_cse_margin.png
@cli        tensaku gate -c /home/esakit25/work/tensaku/configs/exp_al_hitl.yaml [--conf msp|trust ...]
@notes      ä¾å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæœªå®Ÿè£…ã§ã‚‚å‹•ãã‚ˆã†ã€å†…éƒ¨å®Ÿè£…ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ç”¨æ„ï¼ˆcalibration/trust ç„¡ã—ã§ã‚‚å®Ÿè¡Œå¯ï¼‰ã€‚
"""
from __future__ import annotations

import argparse
import dataclasses
import math
import os
import sys
import time
from typing import Iterable, Optional, Tuple

import numpy as np
import pandas as pd

# å¯èƒ½ãªã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ä½¿ã†ï¼ˆç„¡ã‘ã‚Œã°å†…éƒ¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    from tensaku import metrics as _metrics
except Exception:  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    _metrics = None

try:
    from tensaku import calibration as _calib
except Exception:
    _calib = None

try:
    from tensaku import trustscore as _trust
except Exception:
    _trust = None

# ğŸ”§ 1) å…ˆé ­ä»˜è¿‘ï¼ˆimportã®ä¸‹ï¼‰ã«ãƒ˜ãƒ«ãƒ‘ã‚’è¿½åŠ ï¼ˆé‡è¤‡ãŒã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—å¯ï¼‰
CONF_PREFIX = "conf_"

def _subset_accept_hold(df_pool, mask, conf_prefix: str = CONF_PREFIX):
    """mask(1=accept/0=hold) ã§ DataFrame ã‚’äºŒåˆ†ã—ã€ä¿å­˜ç”¨ã®æœ€å°åˆ—ã«æ•´å½¢ã™ã‚‹ã€‚"""
    if not isinstance(mask, (list, tuple, np.ndarray, pd.Series)):
        raise RuntimeError("mask must be sequence-like (0/1).")
    mask = np.array(mask).astype(int)
    if len(mask) != len(df_pool):
        raise RuntimeError(f"mask length mismatch: mask={len(mask)} df={len(df_pool)}")
    cols_conf = [c for c in df_pool.columns if c.startswith(conf_prefix)]
    cols_base = [c for c in ["id", "y_pred"] if c in df_pool.columns]
    cols = cols_base + cols_conf
    df_accept = df_pool[mask == 1][cols].copy()
    df_hold   = df_pool[mask == 0][cols].copy()
    return df_accept, df_hold

def _load_pool_preds(out_dir: str) -> pd.DataFrame:
    """preds_detail.csv ãŒç„¡ã‘ã‚Œã° pool_preds.csv ã‚’æ¢ã™å¾Œæ–¹äº’æ›ãƒ­ãƒ¼ãƒ€ã€‚"""
    p1 = os.path.join(out_dir, "preds_detail.csv")
    p2 = os.path.join(out_dir, "pool_preds.csv")
    for p in (p1, p2):
        if os.path.isfile(p):
            df = pd.read_csv(p)
            if "y_pred" not in df.columns:
                raise RuntimeError(f"missing column y_pred in {p}")
            return df
    raise RuntimeError(f"not found preds file: {p1} or {p2}")



# ---------------------------
# å°ã•ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------
def _rmse(pred: np.ndarray, y: np.ndarray) -> float:
    return float(np.sqrt(np.mean((pred - y) ** 2)))


def _qwk(pred: np.ndarray, y: np.ndarray, n_class: Optional[int] = None) -> float:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®ç°¡æ˜“QWKï¼ˆsklearnï¼‰
    try:
        from sklearn.metrics import cohen_kappa_score
        return float(cohen_kappa_score(y, pred, weights="quadratic"))
    except Exception:
        return float("nan")


def _cse_rate(pred: np.ndarray, y: np.ndarray, abs_err: int) -> float:
    return float(np.mean(np.abs(pred - y) >= abs_err))


def _softmax(logits: np.ndarray, T: float = 1.0) -> np.ndarray:
    z = logits / float(T)
    z = z - z.max(axis=1, keepdims=True)
    e = np.exp(z)
    return e / e.sum(axis=1, keepdims=True)


def _now_str() -> str:
    return time.strftime("%Y-%m-%d %H:%M:%S")


def _ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def _read_yaml(path: str) -> dict:
    import yaml
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def _pick_conf_column(df: pd.DataFrame, conf_name: str) -> str:
    """
    conf_name='msp' ãªã‚‰ conf_msp ã‚’å„ªå…ˆã€å­˜åœ¨ã—ãªã‘ã‚Œã° conf ã£ã½ã„åˆ—ã‹ã‚‰æœ€å¤§å€¤ã‚’é¸ã¶ã€‚
    """
    key = f"conf_{conf_name}"
    if key in df.columns:
        return key
    # ã‚†ã‚‹ã„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    candidates = [c for c in df.columns if c.startswith("conf_")]
    if len(candidates) == 1:
        return candidates[0]
    # æœ€å¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return key  # ãŸã¨ãˆç„¡ãã¦ã‚‚ã“ã®åå‰ã§å¾Œæ®µãŒã‚ã‹ã‚‹


# ---------------------------
# API: Temperature on dev
# ---------------------------
def fit_temperature_on_dev(dev_df: pd.DataFrame, logits_prefix: str = "logits_", label_col: str = "y_true") -> Optional[float]:
    """
    devä¸Šã®logits_* ã‹ã‚‰æ¸©åº¦Tã‚’æ¨å®šã€‚logitsåˆ—ãŒç„¡ã„å ´åˆã¯ None ã‚’è¿”ã™ã€‚
    """
    logit_cols = [c for c in dev_df.columns if c.startswith(logits_prefix)]
    if not logit_cols or label_col not in dev_df.columns:
        return None

    logits = dev_df[logit_cols].to_numpy(dtype=np.float64)
    labels = dev_df[label_col].to_numpy(dtype=int)

    if _calib and hasattr(_calib, "tune_temperature"):
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè£…ãŒã‚ã‚‹å ´åˆ
        return float(_calib.tune_temperature(logits, labels))
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: 0.5ï½3.0 ã‚’0.1åˆ»ã¿ã§ECEæœ€å°ã‚’æ¢ç´¢ï¼ˆç°¡æ˜“ï¼‰
        def ece_of_T(T: float) -> float:
            p = _softmax(logits, T=T)
            conf = p.max(axis=1)
            pred = p.argmax(axis=1)
            bins = np.linspace(0.0, 1.0, 16)
            idx = np.digitize(conf, bins, right=True)
            ece = 0.0
            for b in range(len(bins)):
                m = idx == b
                if not np.any(m):
                    continue
                acc = np.mean(pred[m] == labels[m])
                gap = abs(acc - np.mean(conf[m]))
                ece += gap * (np.sum(m) / len(conf))
            return ece

        Ts = np.arange(0.5, 3.01, 0.1)
        eces = [ece_of_T(float(T)) for T in Ts]
        return float(Ts[int(np.argmin(eces))])


# ---------------------------
# API: compute_confidences
# ---------------------------
def compute_confidences(df: pd.DataFrame, conf_name: str, T: Optional[float] = None,
                        logits_prefix: str = "logits_") -> np.ndarray:
    """
    confåˆ—ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€‚ãªã‘ã‚Œã° logits ã‹ã‚‰ (æ¸©åº¦Tä»˜ãã§) MSP ã‚’è¨ˆç®—ã€‚
    """
    col = _pick_conf_column(df, conf_name)
    if col in df.columns:
        return df[col].to_numpy(dtype=float)

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: logits_* ã‹ã‚‰ MSP ã‚’ä½œã‚‹
    logit_cols = [c for c in df.columns if c.startswith(logits_prefix)]
    if logit_cols:
        logits = df[logit_cols].to_numpy(dtype=np.float64)
        p = _softmax(logits, 1.0 if T is None else float(T))
        return p.max(axis=1)

    # ã™ã¹ã¦ç„¡ã„å ´åˆã¯å®šæ•°ï¼ˆå—ã‘å…¥ã‚Œã‚¼ãƒ­å›é¿ã®ãŸã‚ï¼‰â€»å®Ÿå‹™ã§ã¯è­¦å‘Š
    return np.zeros(len(df), dtype=float)


# ---------------------------
# API: score_trust
# ---------------------------
def score_trust(df_pool: pd.DataFrame) -> Optional[np.ndarray]:
    """
    TrustScore ã‚’è¨ˆç®—ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® trustscore å®Ÿè£…ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ã€‚
    ã“ã“ã§ã¯ conf_trust åˆ—ãŒã‚ã‚Œã°ãã‚Œã‚’è¿”ã—ã€ç„¡ã‘ã‚Œã° Noneã€‚
    """
    if "conf_trust" in df_pool.columns:
        return df_pool["conf_trust"].to_numpy(dtype=float)
    # å°†æ¥: _trust ã‚’ä½¿ã£ã¦ CLSåŸ‹ã‚è¾¼ã¿ã‹ã‚‰ç®—å‡º
    return None


# ---------------------------
# API: find_tau_for_constraint
# ---------------------------
def find_tau_for_constraint(y_pred: np.ndarray, y_true: np.ndarray, conf: np.ndarray,
                            eps: float, cse_abs_err: int, higher_is_better: bool = True) -> Tuple[float, float]:
    """
    devä¸Šã§ CSE â‰¤ eps ã‚’æº€ãŸã—ã¤ã¤ coverage æœ€å¤§ã® Ï„ ã‚’æ¢ç´¢ã€‚
    æˆ»ã‚Šå€¤: (best_coverage, tau)ã€‚æº€ãŸã›ãªã„å ´åˆã¯ (0.0, +inf / -inf) ã‚’è¿”ã™ã€‚
    """
    n = len(conf)
    order = np.argsort(conf * (1 if higher_is_better else -1))[::-1]  # é™é †ï¼ˆhigher=Trueï¼‰/æ˜‡é †ï¼ˆFalseï¼‰
    y_pred_sorted = y_pred[order]
    y_true_sorted = y_true[order]
    conf_sorted = conf[order]

    best_cov = 0.0
    best_tau = -math.inf if higher_is_better else math.inf

    for k in range(1, n + 1):
        cse = _cse_rate(y_pred_sorted[:k], y_true_sorted[:k], cse_abs_err)
        cov = k / n
        if cse <= eps and cov >= best_cov:
            best_cov = cov
            best_tau = conf_sorted[k - 1]

    if best_cov == 0.0:
        return 0.0, (math.inf if higher_is_better else -math.inf)
    return best_cov, float(best_tau)


# ---------------------------
# API: decide_mask
# ---------------------------
def decide_mask(conf: np.ndarray, tau: float, higher_is_better: bool = True) -> np.ndarray:
    """
    conf ã¨ Ï„ ã‹ã‚‰ accept(1)/hold(0) ã®ãƒã‚¹ã‚¯ã‚’è¿”ã™ã€‚
    """
    if higher_is_better:
        return (conf >= tau).astype(np.int32)
    else:
        return (conf <= tau).astype(np.int32)


# ---------------------------
# API: save_gate_csv
# ---------------------------
def save_gate_csv(out_dir: str, summary_row: dict,
                  df_accept: pd.DataFrame, df_hold: pd.DataFrame) -> None:
    _ensure_dir(out_dir)
    # hitl_summary.csv ã¸è¿½è¨˜
    path_sum = os.path.join(out_dir, "hitl_summary.csv")
    row = {**summary_row}
    row["timestamp"] = _now_str()
    if os.path.exists(path_sum):
        pd.DataFrame([row]).to_csv(path_sum, mode="a", header=False, index=False)
    else:
        pd.DataFrame([row]).to_csv(path_sum, index=False)

    # accept/hold æ˜ç´°
    df_accept.to_csv(os.path.join(out_dir, "accept.csv"), index=False)
    df_hold.to_csv(os.path.join(out_dir, "hold.csv"), index=False)


# ---------------------------
# å¯è¦–åŒ–ï¼ˆæœ€å°ç‰ˆï¼‰
# ---------------------------
def _save_curves(out_dir: str, y_true: np.ndarray, y_pred: np.ndarray, conf: np.ndarray, cse_abs_err: int) -> None:
    """
    coverageâ€“RMSE / coverageâ€“CSE ã‚’æãæœ€å°ç‰ˆã€‚æ—¢å­˜ plots ãŒã‚ã‚Œã°ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚
    """
    import matplotlib.pyplot as plt

    order = np.argsort(conf)[::-1]  # é«˜ç¢ºä¿¡åº¦ã‹ã‚‰é †ã«æ¡ç”¨
    y_true_s = y_true[order]
    y_pred_s = y_pred[order]
    conf_s = conf[order]

    covs, rmses, cses = [], [], []
    for k in range(1, len(conf_s) + 1):
        covs.append(k / len(conf_s))
        rmses.append(_rmse(y_pred_s[:k], y_true_s[:k]))
        cses.append(_cse_rate(y_pred_s[:k], y_true_s[:k], cse_abs_err))

    # RMSEæ›²ç·š
    plt.figure()
    plt.plot(covs, rmses)
    plt.xlabel("coverage")
    plt.ylabel("RMSE")
    plt.title("coverageâ€“RMSE")
    _ensure_dir(out_dir)
    plt.savefig(os.path.join(out_dir, "curve_coverage_rmse.png"))
    plt.close()

    # CSEæ›²ç·š
    plt.figure()
    plt.plot(covs, cses)
    plt.axhline(0.02, linestyle="--")
    plt.axhline(0.05, linestyle="--")
    plt.xlabel("coverage")
    plt.ylabel(f"CSE(|err|â‰¥{cse_abs_err})")
    plt.title("coverageâ€“CSE")
    plt.savefig(os.path.join(out_dir, "curve_coverage_cse_margin.png"))
    plt.close()


# ---------------------------
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# ---------------------------
@dataclasses.dataclass
class GateConfig:
    conf_name: str = "msp"
    cse_abs_err: int = 2
    eps_list: Tuple[float, ...] = (0.02, 0.05)
    accept_policy: str = "tau"      # æœªæ¥æ‹¡å¼µç”¨
    pseudo_label_thresh: Optional[float] = None
    higher_is_better: bool = True


def _load_io(cfg: dict) -> Tuple[str, str, pd.DataFrame, pd.DataFrame, GateConfig]:
    data_dir = cfg.get("data_dir") or cfg.get("DATA_DIR")
    out_dir = cfg.get("outputs") or cfg.get("OUT_DIR") or os.path.join(os.getcwd(), "outputs")

    gate_cfg = cfg.get("gate", {}) or {}
    g = GateConfig(
        conf_name=gate_cfg.get("conf_name", "msp"),
        cse_abs_err=int(gate_cfg.get("cse_abs_err", 2)),
        eps_list=tuple(gate_cfg.get("eps_list", [0.02, 0.05])),
        accept_policy=str(gate_cfg.get("accept_policy", "tau")),
        pseudo_label_thresh=gate_cfg.get("pseudo_label_thresh", None),
        higher_is_better=True,  # MSP/Trust ã¯é«˜ã„ã»ã©è‰¯ã„
    )

    dev_path = os.path.join(out_dir, "dev_detail.csv")
    pool_path = os.path.join(out_dir, "preds_detail.csv")
    if not os.path.isfile(dev_path):
        raise RuntimeError(f"missing: {dev_path}")
    if not os.path.isfile(pool_path):
        raise RuntimeError(f"missing: {pool_path}")

    dev_df = pd.read_csv(dev_path)
    pool_df = pd.read_csv(pool_path)
    return out_dir, data_dir, dev_df, pool_df, g


def run(argv: Optional[Iterable[str]] = None, cfg: Optional[dict] = None) -> int:
    """
    CLIã‚¨ãƒ³ãƒˆãƒªã€‚ä¾‹:
      tensaku gate -c /home/esakit25/work/tensaku/configs/exp_al_hitl.yaml --conf msp
    """
    parser = argparse.ArgumentParser(prog="tensaku gate", description="HITL gate (devã§Ï„æ¢ç´¢â†’pool/testã¸é©ç”¨)")
    parser.add_argument("-c", "--config", type=str, required=(cfg is None), help="YAML config path")
    parser.add_argument("--conf", type=str, choices=["msp", "trust", "entropy", "energy", "margin"], default=None)
    parser.add_argument("--eps", type=float, nargs="*", default=None, help="CSEä¸Šé™ã®å€™è£œï¼ˆä¾‹: 0.02 0.05ï¼‰")
    parser.add_argument("--cse-abs-err", type=int, default=None)
    parser.add_argument("--no-calib", action="store_true", help="æ¸©åº¦æ ¡æ­£ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    parser.add_argument("--save-fig", action="store_true")
    # â˜… è¿½åŠ 
    parser.add_argument("--no-infer", action="store_true", help="å†…éƒ¨æ¨è«–ã‚’ä¸€åˆ‡è¡Œã‚ãšã€æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ä½¿ç”¨ã™ã‚‹")
    parser.add_argument("--preds", type=str, default=None, help="pooläºˆæ¸¬CSVï¼ˆpreds_detail.csväº’æ›ï¼‰ã‚’æ˜ç¤ºæŒ‡å®š")
    args, _ = parser.parse_known_args(list(argv) if argv is not None else None)

    # è¨­å®šãƒ­ãƒ¼ãƒ‰
    yml = {} if cfg is None else cfg
    if cfg is None:
        yml = _read_yaml(args.config)
    out_dir, data_dir, dev_df, pool_df, g = _load_io(yml)

    # å¼•æ•°ã§ä¸Šæ›¸ã
    if args.conf:
        g.conf_name = args.conf
    if args.eps:
        g.eps_list = tuple(float(x) for x in args.eps)
    if args.cse_abs_err is not None:
        g.cse_abs_err = int(args.cse_abs_err)

    # 1) æ¸©åº¦æ¨å®šï¼ˆä»»æ„ï¼‰
    T = None
    if not args.no_calib:
        T = fit_temperature_on_dev(dev_df)  # å¤±æ•—(None)ã§ã‚‚ç¶šè¡ŒOK

    # 2) dev/pool ã®ä¿¡é ¼åº¦åˆ—ã®æ±ºå®š
    conf_dev = compute_confidences(dev_df, g.conf_name, T=T)

    # â˜… poolã®ç¢ºå®šï¼š--preds > pool_df > ï¼ˆæœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦æ—¢å®šãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢ï¼‰
    if args.preds:
        df_pool = pd.read_csv(args.preds)
    elif pool_df is not None and len(pool_df) > 0:
        df_pool = pool_df
    else:
        # æ—¢å®šã®å‡ºåŠ›å ´æ‰€ã‹ã‚‰æ‹¾ã†ï¼ˆå­˜åœ¨ã—ãªã‘ã‚Œã°æ˜ç¤ºã‚¨ãƒ©ãƒ¼ï¼‰
        try:
            df_pool = _load_pool_preds(out_dir)
        except Exception as e:
            raise RuntimeError(
                f"[gate] pool predictions not found. "
                f"å…ˆã« infer-pool ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€--preds ã§æ˜ç¤ºã—ã¦ãã ã•ã„: {e}"
            )

    # å†æ¨è«–ã®å®Œå…¨æŠ‘æ­¢
    if args.no_infer:
        print("[gate] --no-infer: å†…éƒ¨æ¨è«–ã¯è¡Œã„ã¾ã›ã‚“ï¼ˆæ—¢å­˜CSVã®ã¿ä½¿ç”¨ï¼‰")

    # poolå´ã®ä¿¡é ¼åº¦
    conf_pool = compute_confidences(df_pool, g.conf_name, T=T)
    if g.conf_name == "trust":
        tr = score_trust(df_pool)
        if tr is not None:
            conf_pool = tr

    # devã®çœŸå€¤ãƒ»äºˆæ¸¬
    y_true_dev = dev_df["y_true"].to_numpy(int)
    y_pred_dev = dev_df["y_pred"].to_numpy(int)

    # poolã®äºˆæ¸¬
    if "y_pred" not in df_pool.columns:
        raise RuntimeError("df_pool ã« y_pred åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆpreds_detailäº’æ›ã®CSVã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼‰")
    y_pred_pool = df_pool["y_pred"].to_numpy(int)

    # é›†è¨ˆ
    all_rows = []
    best_for_plot = None

    for eps in g.eps_list:
        cov_dev, tau = find_tau_for_constraint(
            y_pred_dev, y_true_dev, conf_dev,
            eps=eps, cse_abs_err=g.cse_abs_err,
            higher_is_better=g.higher_is_better
        )

        # --- Ï„ã§äºŒåˆ†ï¼ˆpool/testï¼‰ ---
        mask_te = decide_mask(conf_pool, tau, higher_is_better=g.higher_is_better)
        df_accept, df_hold = _subset_accept_hold(df_pool, mask_te, conf_prefix=CONF_PREFIX)

        # --- devå´ã‚‚ Ï„ã‚’é©ç”¨ã—ã¦â€œå—ã‘å…¥ã‚Œã‚µãƒ–ã‚»ãƒƒãƒˆâ€å“è³ª ---
        mask_dev = decide_mask(conf_dev, tau, higher_is_better=g.higher_is_better)
        if mask_dev.sum() > 0:
            y_pred_dev_acc = y_pred_dev[mask_dev == 1]
            y_true_dev_acc = y_true_dev[mask_dev == 1]
            cse_at_tau = _cse_rate(y_pred_dev_acc, y_true_dev_acc, g.cse_abs_err)
            rmse_at_tau = _rmse(y_pred_dev_acc, y_true_dev_acc)
            n_class = int(max(y_true_dev.max(), y_pred_dev.max()) + 1)
            qwk_at_tau = _qwk(y_pred_dev_acc, y_true_dev_acc, n_class=n_class)
            coverage_dev = float(mask_dev.mean())
        else:
            cse_at_tau = float("nan")
            rmse_at_tau = float("nan")
            qwk_at_tau = float("nan")
            coverage_dev = 0.0

        row = dict(
            eps=float(eps),
            tau=float(tau),
            coverage=float(float(mask_te.mean())),  # pool/test å´ coverage
            CSE=float(cse_at_tau),                  # devå—ã‘å…¥ã‚Œã‚µãƒ–ã‚»ãƒƒãƒˆã®CSE
            RMSE=float(rmse_at_tau),                # devå—ã‘å…¥ã‚Œã‚µãƒ–ã‚»ãƒƒãƒˆã®RMSE
            QWK=float(qwk_at_tau),                  # devå—ã‘å…¥ã‚Œã‚µãƒ–ã‚»ãƒƒãƒˆã®QWK
            coverage_dev=float(coverage_dev),       # devå´ coverageï¼ˆå‚è€ƒï¼‰
            conf_name=g.conf_name,
            cse_abs_err=int(g.cse_abs_err),
        )

        cols_conf = [c for c in df_accept.columns if c.startswith(CONF_PREFIX)]
        save_gate_csv(
            out_dir,
            row,
            df_accept[["id", "y_pred"] + cols_conf] if "id" in df_accept.columns else df_accept,
            df_hold  [["id", "y_pred"] + cols_conf] if "id" in df_hold.columns   else df_hold,
        )

        all_rows.append(row)
        if best_for_plot is None:
            best_for_plot = (y_true_dev, y_pred_dev, conf_dev)

    if args.save_fig and best_for_plot is not None:
        _save_curves(out_dir, *best_for_plot, cse_abs_err=g.cse_abs_err)

    print(f"[gate] done. summary rows: {len(all_rows)}  -> {os.path.join(out_dir,'hitl_summary.csv')}")
    return 0



if __name__ == "__main__":
    sys.exit(run())
